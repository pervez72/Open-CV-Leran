{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXWRR7cqbybEaGY1NUJD0J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tensor DataTypes\n","![](https://drive.google.com/uc?id=1TbTCC-akX_MU9ViiIIeBJftoImsCK2Hd)"],"metadata":{"id":"aWkgC9RFtiGC"}},{"cell_type":"code","source":["# data types for tensors\n","'''\n","* floating -- for most deep learning tasks ---> float32, float64, float16\n","* integers - for categorical data and indices --> int32, int64, int8\n","* booleans - mask or logical operation\n","* Complex number - advanced computation --> complex64, complex128\n","\n","memory consumption : float16 << float32 << float64\n","computation : lower precision will be faster on gpu\n","numberical precision : float64 is more precise than float32\n","'''"],"metadata":{"id":"ctbQEaoLtjdn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"zskQfkLIwOya","executionInfo":{"status":"ok","timestamp":1737561808582,"user_tz":-330,"elapsed":4244,"user":{"displayName":"nimoy","userId":"12145814232676261569"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["default_tensor = torch.tensor([1.5, 2.5, 3.5])\n","print(default_tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrnffgiLwP_X","executionInfo":{"status":"ok","timestamp":1737561857705,"user_tz":-330,"elapsed":3,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"15bb533e-a331-407d-ff8a-46103f76c91e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n"]}]},{"cell_type":"code","source":["float_tensor = torch.tensor([1.5, 2.5, 3.5], dtype=torch.float64)\n","print(float_tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poE7dFG2wdQg","executionInfo":{"status":"ok","timestamp":1737561897888,"user_tz":-330,"elapsed":401,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"60fe5f00-ca39-4c02-ab36-064160f371ac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float64\n"]}]},{"cell_type":"code","source":["int_tensor = torch.tensor([1.5, 2.5, 3.5], dtype=torch.int32)\n","print(int_tensor.dtype)\n","print(int_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1z5lZ_VwnbA","executionInfo":{"status":"ok","timestamp":1737561948411,"user_tz":-330,"elapsed":510,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"16e632fc-2f2c-46c9-aa2e-362f9d159418"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.int32\n","tensor([1, 2, 3], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["int_tensor = torch.tensor([1, 2, 3])\n","print(int_tensor.dtype)\n","print(int_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFVb6DMUwxNw","executionInfo":{"status":"ok","timestamp":1737561979063,"user_tz":-330,"elapsed":368,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"2bf878c9-d28a-4fef-f0d0-e9ff84bb2257"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.int64\n","tensor([1, 2, 3])\n"]}]},{"cell_type":"code","source":["bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)\n","print(bool_tensor.dtype)\n","print(bool_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VG_cmfXiw7S5","executionInfo":{"status":"ok","timestamp":1737562060604,"user_tz":-330,"elapsed":564,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"49d61b62-6cf4-425c-93b4-456a7eb3ee1a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.bool\n","tensor([ True, False,  True])\n"]}]},{"cell_type":"code","source":["float_tensor = torch.tensor([1.5, 2.5, 3.5])\n","print(float_tensor.dtype)\n","print(float_tensor)\n","\n","int_tensor = float_tensor.to(torch.int64)\n","print(int_tensor.dtype)\n","print(int_tensor)\n","\n","int_tensor = torch.tensor([0,1,2,0, -1])\n","bool_tensor = int_tensor.to(torch.bool)\n","print(bool_tensor.dtype)\n","print(bool_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hQRSJRrxJ4x","executionInfo":{"status":"ok","timestamp":1737562239077,"user_tz":-330,"elapsed":343,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"d912f00e-d94b-4b8e-beb0-434901dfc53e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n","tensor([1.5000, 2.5000, 3.5000])\n","torch.int64\n","tensor([1, 2, 3])\n","torch.bool\n","tensor([False,  True,  True, False,  True])\n"]}]},{"cell_type":"markdown","source":["## impact of data type on memory"],"metadata":{"id":"ov3asgfryFAy"}},{"cell_type":"code","source":["float32_tensor = torch.ones(1000, dtype=torch.float32)\n","float64_tensor = torch.ones(1000, dtype=torch.float64)\n","\n","# tensor.element_size()\n","# element_size() --> gives you the size of one element in bytes\n","# nelement() --> gives the total number of elements in tensor\n","\n","print(float32_tensor.element_size())\n","print(float32_tensor.nelement())\n","print(\"Memory used by float32 tensor : \", float32_tensor.element_size() * float32_tensor.nelement(), \" bytes\")\n","print(\"Memory used by float64 tensor : \", float64_tensor.element_size() * float64_tensor.nelement(), \" bytes\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtvgs136xXlC","executionInfo":{"status":"ok","timestamp":1737562583057,"user_tz":-330,"elapsed":1089,"user":{"displayName":"nimoy","userId":"12145814232676261569"}},"outputId":"42070a46-aa5e-45cc-c113-2747d47d5c07"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","1000\n","Memory used by float32 tensor :  4000  bytes\n","Memory used by float64 tensor :  8000  bytes\n"]}]},{"cell_type":"code","source":["# float32 --> default for most NN models\n","# float64 --> high precision computation\n","# int32 --> general purpose integer\n","# int64 --> tensor indices\n","# int8, int16 --> reduce memory usage\n","# bool --> mask and logical operation\n","# float16 --> half precision of your default floating dtype, reduce memory usage\n","# complex64 --> advanced computation"],"metadata":{"id":"TUGMuvZGzAzm"},"execution_count":null,"outputs":[]}]}